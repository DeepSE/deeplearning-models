{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('.venv': venv)",
      "language": "python",
      "name": "python37364bitvenvvenv7b03464ca52642a09f5ea3f892125398"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "logistic-regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepSE/deeplearning-models/blob/master/pytorch_ipynb/basic-ml/logistic-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zp9vuP-AsLd",
        "colab_type": "text"
      },
      "source": [
        "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
        "- Author: Sebastian Raschka\n",
        "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o7GULZOBZxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "624ca7a0-841b-42f8-fe4a-e290529df9f4"
      },
      "source": [
        "!pip install -q IPython\n",
        "!pip install -q ipykernel\n",
        "!pip install -q torch\n",
        "!pip install -q watermark\n",
        "!pip install -q matplotlib\n",
        "!pip install -q tensorwatch\n",
        "!pip install -q sklearn\n",
        "!pip install -q pandas\n",
        "!pip install -q pydot\n",
        "!pip install -q hiddenlayer\n",
        "!pip install -q graphviz\n",
        "!pip install -q torchvision\n",
        "!pip install -q torchtext"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▊                              | 10kB 20.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 51kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 61kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 71kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 92kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 133kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 143kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 153kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 163kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 174kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 184kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 8.0MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |██▌                             | 10kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 31.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 35.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40kB 33.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71kB 18.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 16.2MB/s \n",
            "\u001b[?25h  Building wheel for tensorwatch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pydotz (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "QJQPAzOlAsLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "3affde45-a331-4840-ced4-88eb90b8b871"
      },
      "source": [
        "%load_ext watermark\n",
        "%watermark -a 'Sebastian Raschka' -v -p torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cef6222f7380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext watermark'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"watermark -a 'Sebastian Raschka' -v -p torch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-63>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'watermark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUtJ6qP9AsLm",
        "colab_type": "text"
      },
      "source": [
        "- Runs on CPU or GPU (if available)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohPY1L9DAsLn",
        "colab_type": "text"
      },
      "source": [
        "# Model Zoo -- Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGS_aC2cAsLo",
        "colab_type": "text"
      },
      "source": [
        "Implementation of *classic* logistic regression for binary class labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUcQdQkXAsLp",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIf6X212AsLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbUOSDwcAsLv",
        "colab_type": "text"
      },
      "source": [
        "## Preparing a toy dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2waW6yPAsLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "a199e186-5626-4421-95bc-69e60c0e71f7"
      },
      "source": [
        "##########################\n",
        "### DATASET\n",
        "##########################\n",
        "\n",
        "ds = np.lib.DataSource()\n",
        "fp = ds.open('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')\n",
        "\n",
        "x = np.genfromtxt(BytesIO(fp.read().encode()), delimiter=',', usecols=range(2), max_rows=100)\n",
        "y = np.zeros(100)\n",
        "y[50:] = 1\n",
        "\n",
        "np.random.seed(1)\n",
        "idx = np.arange(y.shape[0])\n",
        "np.random.shuffle(idx)\n",
        "X_test, y_test = x[idx[:25]], y[idx[:25]]\n",
        "X_train, y_train = x[idx[25:]], y[idx[25:]]\n",
        "mu, std = np.mean(X_train, axis=0), np.std(X_train, axis=0)\n",
        "X_train, X_test = (X_train - mu) / std, (X_test - mu) / std\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(7, 2.5))\n",
        "ax[0].scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1])\n",
        "ax[0].scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1])\n",
        "ax[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1])\n",
        "ax[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1])\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x180 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZis59tPAsL1",
        "colab_type": "text"
      },
      "source": [
        "## Low-level implementation with manual gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XKUolctAsL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def custom_where(cond, x_1, x_2):\n",
        "    return (cond * x_1) + ((1-cond) * x_2)\n",
        "\n",
        "\n",
        "class LogisticRegression1():\n",
        "    def __init__(self, num_features):\n",
        "        self.num_features = num_features\n",
        "        self.weights = torch.zeros(num_features, 1, \n",
        "                                   dtype=torch.float32, device=device)\n",
        "        self.bias = torch.zeros(1, dtype=torch.float32, device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        linear = torch.add(torch.mm(x, self.weights), self.bias)\n",
        "        probas = self._sigmoid(linear)\n",
        "        return probas\n",
        "        \n",
        "    def backward(self, probas, y):  \n",
        "        errors = y - probas.view(-1)\n",
        "        return errors\n",
        "            \n",
        "    def predict_labels(self, x):\n",
        "        probas = self.forward(x)\n",
        "        labels = custom_where(probas >= .5, 1, 0)\n",
        "        return labels    \n",
        "            \n",
        "    def evaluate(self, x, y):\n",
        "        labels = self.predict_labels(x).float()\n",
        "        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]\n",
        "        return accuracy\n",
        "    \n",
        "    def _sigmoid(self, z):\n",
        "        return 1. / (1. + torch.exp(-z))\n",
        "    \n",
        "    def _logit_cost(self, y, proba):\n",
        "        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))\n",
        "        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(1 - proba))\n",
        "        return tmp1 - tmp2\n",
        "    \n",
        "    def train(self, x, y, num_epochs, learning_rate=0.01):\n",
        "        for e in range(num_epochs):\n",
        "            \n",
        "            #### Compute outputs ####\n",
        "            probas = self.forward(x)\n",
        "            \n",
        "            #### Compute gradients ####\n",
        "            errors = self.backward(probas, y)\n",
        "            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))\n",
        "            \n",
        "            #### Update weights ####\n",
        "            self.weights += learning_rate * neg_grad\n",
        "            self.bias += learning_rate * torch.sum(errors)\n",
        "            \n",
        "            #### Logging ####\n",
        "            print('Epoch: %03d' % (e+1), end=\"\")\n",
        "            print(' | Train ACC: %.3f' % self.evaluate(x, y), end=\"\")\n",
        "            print(' | Cost: %.3f' % self._logit_cost(y, self.forward(x)))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "mlnt9D55AsL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "da3733a9-8d9f-42a8-8ec4-292e7c71a945"
      },
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
        "\n",
        "logr = LogisticRegression1(num_features=2)\n",
        "logr.train(X_train_tensor, y_train_tensor, num_epochs=10, learning_rate=0.1)\n",
        "\n",
        "print('\\nModel parameters:')\n",
        "print('  Weights: %s' % logr.weights)\n",
        "print('  Bias: %s' % logr.bias)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-70e9c0e208bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlogr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nModel parameters:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-449337e03b50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m#### Logging ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: %03d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' | Train ACC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' | Cost: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logit_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-449337e03b50>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-449337e03b50>\u001b[0m in \u001b[0;36mpredict_labels\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-449337e03b50>\u001b[0m in \u001b[0;36mcustom_where\u001b[0;34m(cond, x_1, x_2)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFdLvASiAsMA",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "d0TEqGPYAsMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
        "\n",
        "test_acc = logr.evaluate(X_test_tensor, y_test_tensor)\n",
        "print('Test set accuracy: %.2f%%' % (test_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7VHf3mOAsML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################\n",
        "### 2D Decision Boundary\n",
        "##########################\n",
        "\n",
        "w, b = logr.weights, logr.bias\n",
        "\n",
        "x_min = -2\n",
        "y_min = ( (-(w[0] * x_min) - b[0]) \n",
        "          / w[1] )\n",
        "\n",
        "x_max = 2\n",
        "y_max = ( (-(w[0] * x_max) - b[0]) \n",
        "          / w[1] )\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, sharex=True, figsize=(7, 3))\n",
        "\n",
        "ax[0].plot([x_min, x_max], [y_min, y_max])\n",
        "ax[1].plot([x_min, x_max], [y_min, y_max])\n",
        "\n",
        "ax[0].scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='class 0', marker='o')\n",
        "ax[0].scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='class 1', marker='s')\n",
        "\n",
        "ax[1].scatter(X_test[y_test==0, 0], X_test[y_test==0, 1], label='class 0', marker='o')\n",
        "ax[1].scatter(X_test[y_test==1, 0], X_test[y_test==1, 1], label='class 1', marker='s')\n",
        "\n",
        "ax[1].legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcdwOVLQAsMP",
        "colab_type": "text"
      },
      "source": [
        "## Low-level implementation using autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6k7am1rAsMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_where(cond, x_1, x_2):\n",
        "    return (cond * x_1) + ((1-cond) * x_2)\n",
        "\n",
        "\n",
        "class LogisticRegression2():\n",
        "    def __init__(self, num_features):\n",
        "        self.num_features = num_features\n",
        "        \n",
        "        self.weights = torch.zeros(num_features, 1, \n",
        "                                   dtype=torch.float32,\n",
        "                                   device=device,\n",
        "                                   requires_grad=True) # req. for autograd!\n",
        "        self.bias = torch.zeros(1, \n",
        "                                dtype=torch.float32,\n",
        "                                device=device,\n",
        "                                requires_grad=True) # req. for autograd!\n",
        "\n",
        "    def forward(self, x):\n",
        "        linear = torch.add(torch.mm(x, self.weights), self.bias)\n",
        "        probas = self._sigmoid(linear)\n",
        "        return probas\n",
        "                    \n",
        "    def predict_labels(self, x):\n",
        "        probas = self.forward(x)\n",
        "        labels = custom_where((probas >= .5).float(), 1, 0)\n",
        "        return labels    \n",
        "            \n",
        "    def evaluate(self, x, y):\n",
        "        labels = self.predict_labels(x)\n",
        "        accuracy = (torch.sum(labels.view(-1) == y.view(-1))).float() / y.size()[0]\n",
        "        return accuracy\n",
        "    \n",
        "    def _sigmoid(self, z):\n",
        "        return 1. / (1. + torch.exp(-z))\n",
        "    \n",
        "    def _logit_cost(self, y, proba):\n",
        "        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))\n",
        "        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(1 - proba))\n",
        "        return tmp1 - tmp2\n",
        "    \n",
        "    def train(self, x, y, num_epochs, learning_rate=0.01):\n",
        "        \n",
        "        for e in range(num_epochs):\n",
        "            \n",
        "            #### Compute outputs ####\n",
        "            proba = self.forward(x)\n",
        "            cost = self._logit_cost(y, proba)\n",
        "            \n",
        "            #### Compute gradients ####\n",
        "            cost.backward()\n",
        "            \n",
        "            #### Update weights ####\n",
        "            \n",
        "            tmp = self.weights.detach()\n",
        "            tmp -= learning_rate * self.weights.grad\n",
        "            \n",
        "            tmp = self.bias.detach()\n",
        "            tmp -= learning_rate * self.bias.grad\n",
        "            \n",
        "            #### Reset gradients to zero for next iteration ####\n",
        "            self.weights.grad.zero_()\n",
        "            self.bias.grad.zero_()\n",
        "    \n",
        "            #### Logging ####\n",
        "            print('Epoch: %03d' % (e+1), end=\"\")\n",
        "            print(' | Train ACC: %.3f' % self.evaluate(x, y), end=\"\")\n",
        "            print(' | Cost: %.3f' % self._logit_cost(y, self.forward(x)))\n",
        "            \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "TASOgZKVAsMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
        "\n",
        "logr = LogisticRegression2(num_features=2)\n",
        "logr.train(X_train_tensor, y_train_tensor, num_epochs=10, learning_rate=0.1)\n",
        "\n",
        "print('\\nModel parameters:')\n",
        "print('  Weights: %s' % logr.weights)\n",
        "print('  Bias: %s' % logr.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny4rD37TAsMa",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "YWRhbDICAsMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
        "\n",
        "test_acc = logr.evaluate(X_test_tensor, y_test_tensor)\n",
        "print('Test set accuracy: %.2f%%' % (test_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob8uRBqPAsMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################\n",
        "### 2D Decision Boundary\n",
        "##########################\n",
        "\n",
        "w, b = logr.weights, logr.bias\n",
        "\n",
        "x_min = -2\n",
        "y_min = ( (-(w[0] * x_min) - b[0]) \n",
        "          / w[1] )\n",
        "\n",
        "x_max = 2\n",
        "y_max = ( (-(w[0] * x_max) - b[0]) \n",
        "          / w[1] )\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, sharex=True, figsize=(7, 3))\n",
        "\n",
        "ax[0].plot([x_min, x_max], [y_min, y_max])\n",
        "ax[1].plot([x_min, x_max], [y_min, y_max])\n",
        "\n",
        "ax[0].scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='class 0', marker='o')\n",
        "ax[0].scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='class 1', marker='s')\n",
        "\n",
        "ax[1].scatter(X_test[y_test==0, 0], X_test[y_test==0, 1], label='class 0', marker='o')\n",
        "ax[1].scatter(X_test[y_test==1, 0], X_test[y_test==1, 1], label='class 1', marker='s')\n",
        "\n",
        "ax[1].legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaFMa20IAsMk",
        "colab_type": "text"
      },
      "source": [
        "## High-level implementation using the nn.Module API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Eqg0MKAsMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression3(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_features):\n",
        "        super(LogisticRegression3, self).__init__()\n",
        "        self.linear = torch.nn.Linear(num_features, 1)\n",
        "        # initialize weights to zeros here,\n",
        "        # since we used zero weights in the\n",
        "        # manual approach\n",
        "        \n",
        "        self.linear.weight.detach().zero_()\n",
        "        self.linear.bias.detach().zero_()\n",
        "        # Note: the trailing underscore\n",
        "        # means \"in-place operation\" in the context\n",
        "        # of PyTorch\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = self.linear(x)\n",
        "        probas = torch.sigmoid(logits)\n",
        "        return probas\n",
        "\n",
        "model = LogisticRegression3(num_features=2).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATsNJ2CxAsMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import hiddenlayer as hl\n",
        "hl.build_graph(model, torch.zeros([75, 2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaOjEACzAsMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Define cost function and set up optimizer #####\n",
        "cost_fn = torch.nn.BCELoss(reduction='sum')\n",
        "# average_size=False to match results in\n",
        "# manual approach, where we did not normalize\n",
        "# the cost by the batch size\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "AFm9tlSlAsMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comp_accuracy(label_var, pred_probas):\n",
        "    pred_labels = custom_where((pred_probas > 0.5).float(), 1, 0).view(-1)\n",
        "    acc = torch.sum(pred_labels == label_var.view(-1)).float() / label_var.size(0)\n",
        "    return acc\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device).view(-1, 1)\n",
        "print(X_train_tensor.shape)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #### Compute outputs ####\n",
        "    out = model(X_train_tensor)\n",
        "    \n",
        "    #### Compute gradients ####\n",
        "    cost = cost_fn(out, y_train_tensor)\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    \n",
        "    #### Update weights ####  \n",
        "    optimizer.step()\n",
        "    \n",
        "    #### Logging ####      \n",
        "    pred_probas = model(X_train_tensor)\n",
        "    acc = comp_accuracy(y_train_tensor, pred_probas)\n",
        "    print('Epoch: %03d' % (epoch + 1), end=\"\")\n",
        "    print(' | Train ACC: %.3f' % acc, end=\"\")\n",
        "    print(' | Cost: %.3f' % cost_fn(pred_probas, y_train_tensor))\n",
        "\n",
        "\n",
        "    \n",
        "print('\\nModel parameters:')\n",
        "print('  Weights: %s' % model.linear.weight)\n",
        "print('  Bias: %s' % model.linear.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tfXeJUTAsM3",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "SbAwApiGAsM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
        "\n",
        "pred_probas = model(X_test_tensor)\n",
        "test_acc = comp_accuracy(y_test_tensor, pred_probas)\n",
        "\n",
        "print('Test set accuracy: %.2f%%' % (test_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA7cdH92AsNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################\n",
        "### 2D Decision Boundary\n",
        "##########################\n",
        "\n",
        "w, b = logr.weights, logr.bias\n",
        "\n",
        "x_min = -2\n",
        "y_min = ( (-(w[0] * x_min) - b[0]) \n",
        "          / w[1] )\n",
        "\n",
        "x_max = 2\n",
        "y_max = ( (-(w[0] * x_max) - b[0]) \n",
        "          / w[1] )\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, sharex=True, figsize=(7, 3))\n",
        "ax[0].plot([x_min, x_max], [y_min, y_max])\n",
        "ax[1].plot([x_min, x_max], [y_min, y_max])\n",
        "\n",
        "ax[0].scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='class 0', marker='o')\n",
        "ax[0].scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='class 1', marker='s')\n",
        "\n",
        "ax[1].scatter(X_test[y_test==0, 0], X_test[y_test==0, 1], label='class 0', marker='o')\n",
        "ax[1].scatter(X_test[y_test==1, 0], X_test[y_test==1, 1], label='class 1', marker='s')\n",
        "\n",
        "ax[1].legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "vGRTgxxnAsNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%watermark -iv"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}